using Microsoft.ProjectOxford.Face.Contract;
using System;
using System.Collections.Generic;
using System.Linq;
using Windows.Foundation;
using Windows.Graphics.Imaging;
using Windows.Media.FaceAnalysis;
using Microsoft.ProjectOxford.Common;
using Emotion = Microsoft.ProjectOxford.Emotion.Contract.Emotion;

namespace RobbieSenses.Evaluation
{
    /// <summary>
    /// Evaluation object that evaluates the result of multiple input types (APIs) or sensors, binding them together in one central local identity store.
    /// </summary>
    public class IdentityInterpolation
    {
        /// <summary>
        /// When a captured frame from the camera is distorted, faces are not recognized and the frame is handled as a image with no faces in it,
        /// causing this class to drop all tracked identities. To survive these kind of glitches, we start counting when no faces are found (anymore)
        /// and only when the thresold configured in this frame drop tolerance member is reached, we drop the identities.
        /// </summary>
        private const int FrameDropTolerance = 4;

        /// <summary>
        /// Counting the number of subsequent frames found with no faces, used to survive capturing glitches as described for the frame drop tolerance member.
        /// </summary>
        private int noFacesFoundCounter;

        /// <summary>
        /// Stores the local identifier of the latest tracked identity as being the largest face (not the person ID, because it doesn't have to be a recognized person!).
        /// This member is used to keep track of the current largest face, and to detect changes in this variable, so the LargestFaceChanged event can be fired.
        /// </summary>
        private string latestLargestFaceIdentifier;

        /// <summary>
        /// A local identity store, keeping track of all detected (or tracked) faces by the Windows FaceAnalysis namespaces,
        /// complemented by additional info from multiple other sources, like Face Identification and detected Emotion.
        /// </summary>
        public List<TrackedIdentity> Identities;

        /// <summary>
        /// Delegate used for the LargestFaceChanged event, 
        /// </summary>
        /// <param name="personId">The person ID of the identity currently having the largest face.</param>
        public delegate void LargestFaceChangedHandler(Guid personId);

        /// <summary>
        /// Event fired when the largest face detected within the current viewport changed. You can use this to switch sessions for the server communication,
        /// because this event is fired whenever a new person is detected or Robbie switches his interaction from one person to another!
        /// </summary>
        public event LargestFaceChangedHandler LargestFaceChanged;

        /// <summary>
        /// Constructs a new Identity Interpolation object with a new empty local identity store.
        /// </summary>
        public IdentityInterpolation()
        {
            Identities = new List<TrackedIdentity>();
            latestLargestFaceIdentifier = string.Empty;
        }

        /// <summary>
        /// Updates the local identity store with new detected faces data, adding and or removing faces and updating the position of existing ones.
        /// </summary>
        /// <param name="detectedFaces">A list of detected faces as generated by the Windows FaceAnalysis namespace.</param>
        public void Update(IList<DetectedFace> detectedFaces)
        {
            // no identities stored yet, but new faces detected
            if (Identities.Count == 0 && detectedFaces.Count > 0)
            {
                // we've found faces, reset the no faces found counter
                noFacesFoundCounter = 0;

                foreach (var detectedFace in detectedFaces)
                {
                    Identities.Add(new TrackedIdentity(detectedFace.FaceBox));
                }
            }
            // identities stored before, but no faces found (anymore)
            else if (Identities.Count > 0 && detectedFaces.Count == 0)
            {
                noFacesFoundCounter++;

                if (noFacesFoundCounter >= FrameDropTolerance)
                {
                    // if you don't do this, it is more stable, because a longer period not detecting any faces will be ignored,
                    // but this would also mean you could walk out of the viewport, having someone else walking back, being identified as you...
                    // so clearing lost faces is the safest and most accurate approach, having less chance to get false positives
                    Identities.Clear();
                }
            }
            // there is an equal amount of stored identities and detected faces, or less faces than identities (those identities can be dropped then)
            else if (Identities.Count >= detectedFaces.Count)
            {
                // we've found faces, reset the no faces found counter
                noFacesFoundCounter = 0;

                var newPositions = new Dictionary<Guid, DetectedFace>();

                // loop through detected faces (when having more identities than faces (or equal), it is easier to view this from the face perspective)
                foreach (var detectedFace in detectedFaces)
                {
                    var nearest = FindNearestIdentity(detectedFace.FaceBox);
                    newPositions.Add(nearest.Identifier, detectedFace);
                }

                var identitiesToRemove = new List<Guid>();

                // update center points of already tracked identities with newly found face coordinates
                foreach (var identity in Identities)
                {
                    if (newPositions.Keys.Contains(identity.Identifier))
                    {
                        identity.UpdatePosition(newPositions[identity.Identifier].FaceBox);
                    }
                    else
                    {
                        identitiesToRemove.Add(identity.Identifier);
                    }
                }

                // remove identities of which the face tracking has been lost
                foreach (var guid in identitiesToRemove)
                {
                    var identity = Identities.First(id => id.Identifier.Equals(guid));
                    Identities.Remove(identity);
                }
            }
            // there are more detected faces than stored identities, so first map the most likely matches
            // and then create new identities for the newly detected faces
            else
            {
                var newPositions = new Dictionary<Guid, DetectedFace>();

                // loop through stored identities (when having less identities than faces, it is easier to view this from the identity perspective)
                foreach (var identity in Identities)
                {
                    var nearest = identity.FindNearestFace(detectedFaces);
                    newPositions.Add(identity.Identifier, nearest);
                    
                    // consume bound faces (when there's a closest match, remove it to avoid matching the same face again)
                    detectedFaces.Remove(nearest);
                }

                // update center points of already tracked identities with newly found face coordinates
                foreach (var identity in Identities)
                {
                    identity.UpdatePosition(newPositions[identity.Identifier].FaceBox);
                }

                // add new identities for faces not yet known
                foreach (var face in detectedFaces)
                {
                    Identities.Add(new TrackedIdentity(face.FaceBox));
                }
            }
        }

        /// <summary>
        /// Updates the corresponding tracked identity object in the local identity store, used when a detected face is identified as a person.
        /// </summary>
        /// <param name="face">The face as detected by the Cognitive Services Face API (not the Windows FaceAnalysis object).</param>
        /// <param name="person">The person as identified by the Cognitive Services Face API.</param>
        /// <remarks>
        /// Assumes the concerning face is also (or rather, already) detected by the face tracker (Windows FaceAnalysis namespace).
        /// </remarks>
        public void IdentifiedFace(Face face, Person person)
        {
            var identity = FindNearestIdentity(face.FaceRectangle);

            if (identity != null)
            {
                identity.Name = person.Name;
                identity.PersonId = person.PersonId;
                identity.Appearance = face.FaceAttributes;
            }
        }

        /// <summary>
        /// Updates the corresponding tracked identity object in the local identity store, used when emotions are detected for a certain (detected) face.
        /// </summary>
        /// <param name="emotion">The emotion object as generated by the Cognitive Services Emotion API.</param>
        /// <remarks>
        /// Assumes the concerning face is also (or rather, already) detected by the face tracker (Windows FaceAnalysis namespace).
        /// </remarks>
        public void DetectedEmotion(Emotion emotion)
        {
            var identity = FindNearestIdentity(emotion.FaceRectangle);

            if (identity != null)
            {
                identity.EmotionScores = emotion.Scores;
            }
        }

        /// <summary>
        /// Returns the currently largest tracked face, for Robbie to know who to talk to and on whom to focus; null when there are no faces in the current viewport.
        /// </summary>
        /// <returns>The tracked identity object of the largest face that is currently in the viewport.</returns>
        public TrackedIdentity GetLargestFace()
        {
            if (Identities.Count == 0)
            {
                latestLargestFaceIdentifier = string.Empty;
                return null;
            }

            // retrieve the largest face within the viewport by sorting by surface area
            var largestFaceIdentity = Identities.OrderBy(identity => identity.SurfaceArea).Last();

            // check if the identity of the largest face differs from the previous one; if so, fire the changed event
            if (!largestFaceIdentity.Identifier.ToString().Equals(latestLargestFaceIdentifier))
            {
                OnLargestFaceChanged(largestFaceIdentity.PersonId);

                // store the identifier of the newly detected largest face (only required when actually changed
                latestLargestFaceIdentifier = largestFaceIdentity.Identifier.ToString();
            }

            return largestFaceIdentity;
        }

        /// <summary>
        /// Event handler fired when the largest face within the viewport changes.
        /// </summary>
        /// <param name="personId">The person ID of the identity currently having the largest face.</param>
        /// <remarks> This event will only be fired when the largest face is retrieved continuously on each frame capture.</remarks>
        protected virtual void OnLargestFaceChanged(Guid personId)
        {
            var handler = LargestFaceChanged;
            // ReSharper disable once UseNullPropagation
            if (handler != null)
            {
                handler(personId);
            }
        }

        /// <summary>
        /// Returns the point to focus on, being either the largest face in the current viewport, or a negative coordinate if no faces are found.
        /// </summary>
        /// <returns>A point object holding the coordinates of the point to focus on or a negative coordinate if no faces are in the current viewport.</returns>
        public Point GetFocalPoint()
        {
            if (Identities.Count == 0)
            {
                return new Point(-1, -1);
            }

            return GetLargestFace().CenterPoint;
        }

        /// <summary>
        /// Finds the stored identity that is closest to the give bounding box, based on a BitmapBounds object, defining the bounding box.
        /// </summary>
        /// <param name="bounds">The BitmapBounds object defining the rectangle to find the nearest identity for.</param>
        /// <returns>The stored identity object that is the closest to the given bounding box.</returns>
        public TrackedIdentity FindNearestIdentity(BitmapBounds bounds)
        {
            return FindNearestIdentity((int)bounds.X, (int)bounds.Y, (int)bounds.Width, (int)bounds.Height);
        }

        /// <summary>
        /// Finds the stored identity that is closest to the give bounding box, based on a Rectangle object, defining the bounding box.
        /// </summary>
        /// <param name="rectangle">The Rectangle object defining the rectangle to find the nearest identity for.</param>
        /// <returns>The stored identity object that is the closest to the given bounding box.</returns>
        public TrackedIdentity FindNearestIdentity(Rectangle rectangle)
        {
            return FindNearestIdentity(rectangle.Left, rectangle.Top, rectangle.Width, rectangle.Height);
        }

        /// <summary>
        /// Finds the stored identity that is closest to the give bounding box, based on a FaceRectangle object, defining the bounding box.
        /// </summary>
        /// <param name="rectangle">The FaceRectangle object defining the rectangle to find the nearest identity for.</param>
        /// <returns>The stored identity object that is the closest to the given bounding box.</returns>
        public TrackedIdentity FindNearestIdentity(FaceRectangle rectangle)
        {
            return FindNearestIdentity(rectangle.Left, rectangle.Top, rectangle.Width, rectangle.Height);
        }

        /// <summary>
        /// Finds the stored identity that is closest to the give bounding box, based on top left coordinates and size.
        /// </summary>
        /// <param name="x">The x position of the left side of the rectangle.</param>
        /// <param name="y">The y position of the top of the rectangle.</param>
        /// <param name="width">The width of the rectangle.</param>
        /// <param name="height">The height of the rectangle.</param>
        /// <returns>The stored identity object that is the closest to the given bounding box.</returns>
        public TrackedIdentity FindNearestIdentity(int x, int y, int width, int height)
        {
            if (Identities.Count == 0)
            {
                return null;
            }

            var nearestFaceGuid = Guid.Empty;
            var nearestFaceDistance = double.MaxValue;
            foreach (var identity in Identities)
            {
                var faceCenter = GetCenterPoint(x, y, width, height);
                var distance = GetRelativeDistance(identity.CenterPoint, faceCenter);
                if (distance < nearestFaceDistance)
                {
                    nearestFaceGuid = identity.Identifier;
                    nearestFaceDistance = distance;
                }
            }
            return Identities.First(id => id.Identifier.Equals(nearestFaceGuid));
        }

        /// <summary>
        /// Calculates the center point of a rectangle, based on a BitmapBounds object, defining the rectangle.
        /// </summary>
        /// <param name="bounds">The BitmapBounds object defining the rectangle to calculate the center point of.</param>
        /// <returns>The center point of the rectangle.</returns>
        public static Point GetCenterPoint(BitmapBounds bounds)
        {
            return GetCenterPoint((int)bounds.X, (int)bounds.Y, (int)bounds.Width, (int)bounds.Height);
        }

        /// <summary>
        /// Calculates the center point of a rectangle, based on top left coordinates and size.
        /// </summary>
        /// <param name="x">The x position of the left side of the rectangle.</param>
        /// <param name="y">The y position of the top of the rectangle.</param>
        /// <param name="width">The width of the rectangle.</param>
        /// <param name="height">The height of the rectangle.</param>
        /// <returns>The center point of the rectangle.</returns>
        public static Point GetCenterPoint(int x, int y, int width, int height)
        {
            return new Point(
                x + width / 2,
                y + height / 2    
            );
        }

        /// <summary>
        /// Calculates the relative distance between two points in two-dimensional space.
        /// </summary>
        /// <param name="a">The point to calculate the distance from.</param>
        /// <param name="b">The point to calculate the distance to.</param>
        /// <returns></returns>
        /// <remarks>
        /// Doesn't calculate the actual distance, because it doesn't calculate the root of the added squares for performance reasons,
        /// but can be used for comparison purposes; hence the name relative distance.
        /// </remarks>
        public static double GetRelativeDistance(Point a, Point b)
        {
            return (a.X - b.X) * (a.X - b.X) + (a.Y - b.Y) * (a.Y - b.Y);
        }
    }
}
